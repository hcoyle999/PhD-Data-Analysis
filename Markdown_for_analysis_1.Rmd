---
title: "PHD-Data-Analysis"
output: html_document
---

## R Markdown Instructions
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

## Good resoruces for learning R
https://r4ds.had.co.nz/
https://compcogscisydney.org/psyr/scripts.html

## Command shortcuts
Move cursor to console = Ctrl + 2
Move cursor to command editor = Ctrl + 1
Clear console= Ctrl + L
Run the line in the command window = Command + Enter
Run whole script = Command + Shift + S

Other shortcutes are below
https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts

## Useful commands
getwd()- shows you where your wd is
sessionInfo() -gives you an overview of your version, packages loaded etc.
install.packages () - installs packages for you (name must be in "")
library() - loads whatever package you need
par(mfrow=c(X,X)) - displays multiple plots on a page 
detach_package("XX", TRUE) - detach a package (sometimes r gets confused if you have too many loaded)

## General r setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
here<-"/Users/han.coyle/Documents/PHD-Data-Analysis/PHD-Data-Analysis"
setwd(here)
library(tidyverse)
```



## Opening my SPPS database and converting to R file
```{r Open SPSS, include=FALSE}
## the following is to ensure that the SPSS data is loaded correctly so you can see variable labels and value labels 
#load database as a list
setwd(here)
COMBINED_COG_PhD<-haven::read_spss("COMBINED_COG_PhD.sav",user_na=FALSE)
View(COMBINED_COG_PhD)
save(COMBINED_COG_PhD,file="~/Documents/PHD-Data-Analysis/PHD-Data-Analysis/COMBINED_COG_PhD.Rdata")
```

## Calculating descriptive statistics
```{r Descriptive statitics,include=FALSE}
## calculating mean of variables (na.rm is to ignore misisng values,and round is to get it to two decimal places)
round(mean(x=COMBINED_COG_PhD$age,na.rm=TRUE),digits=2)
round(mean(x=COMBINED_COG_PhD$days_post,na.rm=TRUE),digits=2)

#package to assist with descriptive statistics
library(psych)
# larger range of descriptive statistics
describe(age)
# looking at descriptive stats for range of
demo <-cbind(age,education,HADS_Total_BL)
describe(demo)
# change column names
colnames(demo)<- c('Age','Level of Education','Anxiety/Depression')
describe(demo)
#by group
describeBy(demo,group=group)

```

## Data transformation (filter, arrange, select etc) 
```{r Filtering my data, include=FALSE}
# need to load this package or will not work
library(dplyr)
# practicing filtering (this just prints out results, need <- to make a variable, If you want to do both, you can wrap the assignment in parentheses)
age_over_30 <- filter(COMBINED_COG_PhD,age > 30)
(age_under_30 <-filter(COMBINED_COG_PhD, age < 30))

#make dfs for my two groups
control_df <- filter(COMBINED_COG_PhD,group == 1)
mtbi_df <- filter(COMBINED_COG_PhD,group == 2)

#to filter effectively need to know the operators, e.g. >, >=, <, <=, != (not equal), and == (equal).

#filter() only includes rows where the condition is TRUE; it excludes both FALSE and NA values. If you want to preserve missing values, ask for them explicitly:

MFI_10<-filter(COMBINED_COG_PhD,MFI_GF_BL> 10 |is.na(MFI_GF_BL))

# arrange data (instead of selecting rows it changes their order)
library(plyr)
arrange(control, age, education, sex)
#organising in descending order
arrange(control, desc(age))

#select data
 control_dem<-select(control, code,intials, age, education, sex)
 #if want to select all columns between two variables use
  control_dem<-select(control, code:education)
#can rename a column  *this is not working for some reason*
  rename(COMBINED_COG_PhD,intials = initials)
  
#access df by row and or colum
  #access all rows, just age column
  COMBINED_COG_PhD[,'age']
  #access just row 1, all column
  COMBINED_COG_PhD[1,]
  
#add new variables with "mutate"
  #e.g. want a df with just MFI data in it
  MFI_df <- select(COMBINED_COG_PhD, code, intials, starts_with("MFI"))
  #create new variables with diff scores and add these to the df
  MFI_df <- mutate(MFI_df,
        bsl_T1_MFI_GF = MFI_GF_T1 - MFI_GF_BL,
        bsl_T2_MFI_GF = MFI_GF_T2 - MFI_GF_BL)
  #If you only want to keep the new variables, use transmute():
  MFI_df_diff<-transmute(MFI_df, bsl_T1_MFI_GF = MFI_GF_T1 - MFI_GF_BL, bsl_T2_MFI_GF = MFI_GF_T2 - MFI_GF_BL)
  
  #To get grouped summaries
  #first create new df with variables you are interested in seeing 
  group_dem <- group_by(COMBINED_COG_PhD, code, intials, age, education)
  #summarise and apply by group
  summarise(group_dem, meanRPQ = mean(RPQ_13_BL, na.rm = TRUE))
  
  #Combining operations by pipe (makes code easier to read and you dont have to name each intermediate data frame) - this produces a df with the mean RPQ symptom score for control and mtbi and mean coding score.
  # Also good to include a count (n()), or a count of non-missing values (sum(!is.na(x))). That way you can check that youâ€™re not drawing conclusions based on very small amounts of data.
  sympt_speed <- group_dem %>% group_by(group) %>% summarise (count=n(), symptoms= mean(RPQ_13_BL, na.rm=TRUE), processingspeed=mean(Coding_BL,na.rm=TRUE))
  
  #If you need to remove grouping, and return to operations on ungrouped data, use ungroup().
  sympt_speed %>% 
  ungroup()  
  summarise(sympt_speed)

  #Can also do grouped mutates and filters (see section 5.7 of https://r4ds.had.co.nz/transform.html#grouped-summaries-with-summarise for info)

```

## Plotting from online tutorial- not using ggplot
```{r Plotting my data, include=FALSE}
## using regular plot functions
## when you just want to type in the variables
attach(COMBINED_COG_PhD)
## plot adding headings- scatterplot
plot(age,WTAR,main="Age vs WTAR",xlab="WTAR",ylab="age(years)")
#draw a line
abline(0, 1)
#change from circles (1 Circle, 2 Triangle,3 Plus,4 Cross, 5 Diamond, 6 Reverse Triangle etc)
plot(age,WTAR,main="Age vs WTAR",xlab="WTAR",ylab="age(years)",pch=3)

#plot just control group
plot(age[group ==1],WTAR[group == 1],col="Red")

#plot both groups on top of each other
points(age[group ==2],WTAR[group == 2],col="blue")

#plot groups side by side (two windows)
par(mfrow = c(1,2))
plot(age[group ==1],WTAR[group == 1],main= "Control",xlim=c(0,50),ylim=c(0,45))
plot(age[group ==2],WTAR[group == 2],main= "mTBI",xlim=c(0,50),ylim=c(0,45))

mtext(text="WTAR",side=2, adj=1)

#go back to only one window
par(mfrow=c(1,1))

#timeseries plotting ( but for my data it will be for participants)
  plot(COMBINED_COG_PhD$HADS_Total_BL)
  plot(COMBINED_COG_PhD$HADS_Total_BL[group==1])
  hist(age)
  hist(age, breaks=5)
  
  ##box plots
  boxplot(age)
  boxplot(age [group==1],main="Control")
  #box plots side by side
  par(mfrow=c(1,2))
  boxplot(age [group==1],main="Control",ylim=c(15,55))
  boxplot(age [group==2],main="mTBI",ylim=c(15,55))
  
  par(mfrow=c(1,1))
  boxplot(age ~ LOC)
  
  #another way to do this is to use the ~ symbol, (e.g. age by group)
  boxplot(age ~ group, main= "Boxplot of age by group")
```


## ggplot Plotting 
```{r ggplot for my data, include=FALSE}
library(ggplot2)
#plotting two continuous variables
#scatterplots
ggplot(COMBINED_COG_PhD,mapping=aes(x=age, y=education)) + 
geom_point(colour=group)

ggplot(COMBINED_COG_Phd,mapping=aes(x=Coding_BL, y=SymbolSearch_BL)) +
geom_point(colour=group)
#histograms 
ggplot(COMBINED_COG_PhD, mapping=aes(x = education, y=age))+ geom_histogram(stat="identity")
# By default, geom_bar uses stat="count" which makes the height of the bar proportion to the number of cases in each group (or if the weight aethetic is supplied, the sum of the weights). If you want the heights of the bars to represent values in the data, use stat="identity" and map a variable to the y aesthetic.

ggplot(COMBINED_COG_PhD,aes (x=age), na.rm=FALSE) + geom_histogram(binwidth=1)
#line graphs

```
## Worked example (means to ggplot)
```{r practicing with coding data- shaping df, means and ggplot}
#prac example of line graph with means from coding across BL-T2 for both groups
#To get grouped summaries
  #first create new df with variables you are interested in seeing 
BL_T2_coding <- select(COMBINED_COG_PhD, code, intials, Coding_BL, Coding_T1, Coding_T2)
  #summarise and apply by group
  #BL_T2_coding %>%summarise(BL_T2_coding)
  #calculate means
  library(plyr)
  BL_T2_coding <-ddply (BL_T2_coding, .(group), summarize,  BL=mean(Coding_BL,na.rm=TRUE), T1=mean(Coding_T1,na.rm=TRUE), T2=mean(Coding_T2,na.rm=TRUE))
  
  #reshape the datafram
  library(reshape2)
  meltdf <- melt(BL_T2_coding,id.vars  ="group", variable.name = "timepoint",na.rm=TRUE)
  #remove haven labelling (you need to do this because when you import from SPSS you have all varaible value labels which then ggplot can't read)
  library(labelled)
  meltdf_1<-remove_labels(meltdf)
  
  #If you want to change the colum names
  #colnames(meltdf_1)<- c("Group","Timepoint","Processing Speed")
  
  #make a plot
  base<-ggplot(meltdf_1,aes(x = timepoint,y = value)) + 
    geom_point(aes(colour = "Group")) +
    geom_smooth () 
  ## this next step is changing parts of the graph- see page 181 of pdf book for info)  
    base + 
    theme(
      legend.background = element_rect(
      fill = "lemonchiffon",
      colour = "grey50",
      size = 1
      ))
    
## next step is to change Axis labels and to remove the group legend- or change it to say control and mTBI

```

##Hypothesis testing/statistical analysis
# Good resource on normality testing in r
https://www.sheffield.ac.uk/polopoly_fs/1.579191!/file/stcp-karadimitriou-normalR.pdf
```{r testing for normality, echo=FALSE}

##Plotting histograms and ensuring axes are same size
par(mfrow = c(1,2))
hist(WTAR[group==1],probability = T,main="Control WTAR",xlim=c(20,50),ylim=c(0.00,0.10))
hist(WTAR[group==2],probability = T,main="mTBI WTAR",xlim=c(20,50),ylim=c(0.00,0.10))

#Using normal Q-Q plot (better when small sample sizes than a histogram)
qqnorm(WTAR,main="QQ plot of WTAR data",pch=19)
qqline(WTAR)

#Assessing skewedness (negative values indicate left skew and positive indicate right skew) and kurtosis
skewness(age,na.rm=TRUE)
kurtosis(age,na.rm=TRUE)

##Testing for normality (if p> .05 normality can be assumed- use Shapiro Wilk for smaller samples, non normal data means non paramertic tests should be used)
shapiro.test(WTAR)
##not sure how to apply a function to multiple variables and print the ouput all at the same time?? i.e if wanted to check normality for all variableli

##transforming your data- for skewed data common transformations include square root, cube root, and log - see for list of code http://rcompanion.org/handbook/I_12.html
libary(rcompanion)
#Cube transform results in age being normally distributed.
A_cbrt <- sign(age) * abs(age)^(1/3)
hist(A_cbrt)
shapiro.test(A_cbrt)

#Log transform (strongest)
A_log <- log(age) 
hist(A_log)
shapiro.test(A_log)
```
```{r statistical analysis, echo=TRUE}
#parametric tests

#two sample t-test = independent, paired sample t-test = dependent (assessing whether the variance for two samples is equal)

#test for equality of variance (F test to compare the variances of two samples from normal populations)- data must be normal (looking for p>.05 to support the null there is no difference)
shapiro.test(Coding_BL)
var.test(Coding_BL,Coding_T2)

#If variances are assumed equal, then you need to specify var.equal=TRUE when using t.test *two-tailed is the default, but can change* (p<.05 = sig difference in the means)
t.test(Coding_BL,Coding_T1,var.equal = TRUE)
boxplot(Coding_BL,Coding_T1)

#by group (with equal variance)
var.test(Coding_BL~group)
t.test(Coding_BL~ group, var.equal=TRUE)
boxplot(Coding_BL~ group,main="Processing Speed",names=c("control","mTBI"),ylab="Coding Performance", xlab="Baseline")

#with unequal variance - just change var.equal=FALSE

#paired sample t test (for dependent variables)- find the difference between two sets of data (find mean and SD of these differences)- will use df that have been filtered

#as a data checking precaution  
#create df with just controls and coding scores
Coding_long_df<-select(control_df,code,Coding_BL,Coding_T1,Coding_T2)
#create difference score
d<- with(control_df,Coding_T1-Coding_BL)
#run paired sample t-test
t.test(control_df$Coding_BL,control_df$Coding_T1,paired=TRUE,var.equal=TRUE)
#if want to see if coding speed at T1 has improved compared to baseline for both groups seperately (alternative ="greater" is the alternative that x has a larger mean than y)- normality and homogeneity of variance has been shown to hold)
t.test(control_df$Coding_BL,control_df$Coding_T1,paired=TRUE,var.equal=TRUE,alternative="less")
t.test(mtbi_df$Coding_BL,mtbi_df$Coding_T1,paired=TRUE,var.equal=TRUE,alternative="less")

##ANOVA (test equality of variances and equality of means for control group for coding across BL-T1-T2)
#first create data correct data frame
control_df_coding<-select(control_df, code,Coding_BL, Coding_T1,Coding_T2)
control_df_coding<- melt(control_df_coding,id.vars = "code", measure.vars = c("Coding_BL", "Coding_T1","Coding_T2"))
#run the anova
control_cod_aov<-aov(data=control_df_coding, formula=value~ variable)
summary(control_cod_aov)

#visualise the data (even though above is not significant)
boxplot(control_df$Coding_BL,control_df$Coding_T1,control_df$Coding_T2)

#post hoc tests (if p<.05 = sig difference)
TukeyHSD(control_cod_aov)

#for mtbi (be aware there is a lot of missing data that hasn't been controlled for)
#first create data correct data frame
mtbi_df_coding<-select(mtbi_df, code,Coding_BL, Coding_T1,Coding_T2)
mtbi_df_coding<- melt(mtbi_df_coding,id.vars = "code", measure.vars = c("Coding_BL", "Coding_T1","Coding_T2"))
#run the anova
mtbi_cod_aov<-aov(data=mtbi_df_coding, formula=value~ variable)
summary(mtbi_cod_aov)

#visualise the data (even though above is not significant)
boxplot(mtbi_df$Coding_BL,mtbi_df$Coding_T1,mtbi_df$Coding_T2)
#post hoc tests
TukeyHSD(mtbi_cod_aov)

```

#visualising data longitudinally with box plots and in different groups
```{r visualising data longitudinally}
#visualising the data- processing speed
par(mfrow=c(1,2))
boxplot(control_df$Coding_BL,control_df$Coding_T1,control_df$Coding_T2,main= "Processing Speed",names=c("BL","T1","T2"),xlab="Control")
boxplot(mtbi_df$Coding_BL,mtbi_df$Coding_T1,mtbi_df$Coding_T2,main= "Processing Speed",names=c("BL","T1","T2"),xlab="mTBI")

# visualising the data longitudinally- digit span total
par(mfrow=c(1,2))
boxplot(control_df$SS_total_BL,control_df$SS_total_T1,control_df$SS_total_T2,main= "Digit Span Total ",names=c("BL","T1","T2"),xlab="Control")
boxplot(mtbi_df$SS_total_BL,mtbi_df$SS_total_T1,mtbi_df$SS_total_T2,main= "Digit Span Total",names=c("BL","T1","T2"),xlab="mTBI")

par(mfrow=c(1,2))
boxplot(control_df$SS_bck_BL,control_df$SS_bck_T1,control_df$SS_bck_T2,main= "Digit Span BWD ",names=c("BL","T1","T2"),xlab="Control")
boxplot(mtbi_df$SS_bck_BL,mtbi_df$SS_bck_T1,mtbi_df$SS_bck_T2,main= "Digit Span BWD",names=c("BL","T1","T2"),xlab="mTBI")

##ideally would prefer to do this in ggplot but one thing at a time.
